{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7252557,
          "sourceType": "datasetVersion",
          "datasetId": 4202200
        }
      ],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NER: evaluation"
      ],
      "metadata": {
        "id": "t3MVIoXd9Xha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate seqeval\n",
        "!pip install -q transformers[torch]"
      ],
      "metadata": {
        "id": "sEcunOTpKVwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/named-entity/hse-nlp/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfqeOvQP_Y35",
        "outputId": "3bb2a6f1-6cfd-4d75-c2eb-58d869fba97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'hse-nlp' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import defaultdict, Counter\n",
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:07.993950Z",
          "iopub.execute_input": "2023-12-26T06:49:07.994433Z",
          "iopub.status.idle": "2023-12-26T06:49:08.001939Z",
          "shell.execute_reply.started": "2023-12-26T06:49:07.994366Z",
          "shell.execute_reply": "2023-12-26T06:49:08.001054Z"
        },
        "trusted": true,
        "id": "efk_0fQ_9Xhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Выбор модели"
      ],
      "metadata": {
        "id": "X94weNzyVaW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'bert-base/rubert-tiny2-ner-absa-v1' or 'bert-base/rubert-tiny2-ner-absa-v2'\n",
        "\n",
        "model_checkpoint = 'bert-base/rubert-tiny2-ner-absa-v1'"
      ],
      "metadata": {
        "id": "2Bdsc_J8VOHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Пути к файлам"
      ],
      "metadata": {
        "id": "PhbKe7wzVegi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REPLACE with your paths to the test datasets, the gold annotation, and the baseline results\n",
        "\n",
        "path_to_aspects = '/content/hse-nlp/4th_year/Project/dev_aspects.txt'\n",
        "path_to_reviews = '/content/hse-nlp/4th_year/Project/dev_reviews.txt'\n",
        "\n",
        "gold_cats_test_path = '/content/hse-nlp/4th_year/Project/dev_cats.txt'\n",
        "baseline_cats_test_path = '/content/hse-nlp/4th_year/Project/dev_pred_cats.txt'\n",
        "\n",
        "gold_aspects_test_path = '/content/hse-nlp/4th_year/Project/dev_aspects.txt'\n",
        "baseline_aspects_test_path = '/content/hse-nlp/4th_year/Project/dev_pred_aspects.txt'"
      ],
      "metadata": {
        "id": "l-Aqdf7DRJ-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_aspects_and_reviews(path_to_aspects, path_to_reviews):\n",
        "    test_aspects = pd.read_csv(path_to_aspects, sep='\\t', header=None,\n",
        "                names=['review_id', 'category', 'span', 'span_start', 'span_end', 'sentiment'])\n",
        "\n",
        "    test_reviews = pd.read_csv(path_to_reviews, sep='\\t', header=None,\n",
        "                names=['review_id', 'text', 'sentiment'])\n",
        "    return test_aspects, test_reviews"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:08.239369Z",
          "iopub.execute_input": "2023-12-26T06:49:08.240099Z",
          "iopub.status.idle": "2023-12-26T06:49:08.308417Z",
          "shell.execute_reply.started": "2023-12-26T06:49:08.240061Z",
          "shell.execute_reply": "2023-12-26T06:49:08.307350Z"
        },
        "trusted": true,
        "id": "BRIXrzdG9Xhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_aspects, test_reviews = get_aspects_and_reviews(path_to_aspects, path_to_reviews)"
      ],
      "metadata": {
        "id": "isTxg1i4Rb-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate sentiment and aspects labels\n",
        "test_aspects['text_label'] = test_aspects.category + '_' + test_aspects.sentiment"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:08.725917Z",
          "iopub.execute_input": "2023-12-26T06:49:08.726457Z",
          "iopub.status.idle": "2023-12-26T06:49:08.742353Z",
          "shell.execute_reply.started": "2023-12-26T06:49:08.726413Z",
          "shell.execute_reply": "2023-12-26T06:49:08.740958Z"
        },
        "trusted": true,
        "id": "He-CvQtS9Xhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('cointegrated/rubert-tiny2')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:08.930167Z",
          "iopub.execute_input": "2023-12-26T06:49:08.930919Z",
          "iopub.status.idle": "2023-12-26T06:49:09.105421Z",
          "shell.execute_reply.started": "2023-12-26T06:49:08.930873Z",
          "shell.execute_reply": "2023-12-26T06:49:09.103763Z"
        },
        "trusted": true,
        "id": "p0dBLLFk9Xhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_reviews['input_ids'] = test_reviews.text.apply(lambda x: tokenizer([x]).input_ids)\n",
        "\n",
        "test_reviews['tokens'] = test_reviews.text.apply(lambda x: tokenizer([x]).tokens())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:09.376078Z",
          "iopub.execute_input": "2023-12-26T06:49:09.376738Z",
          "iopub.status.idle": "2023-12-26T06:49:10.000346Z",
          "shell.execute_reply.started": "2023-12-26T06:49:09.376701Z",
          "shell.execute_reply": "2023-12-26T06:49:09.998954Z"
        },
        "trusted": true,
        "id": "_GSYqi5E9Xhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['span', 'span_start', 'span_end', 'text_label']:\n",
        "    test_reviews = test_reviews.merge(test_aspects.groupby('review_id')[col].apply(lambda x: list(x)),\n",
        "                                        left_on='review_id',\n",
        "                                        right_index=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:10.058568Z",
          "iopub.execute_input": "2023-12-26T06:49:10.059076Z",
          "iopub.status.idle": "2023-12-26T06:49:10.153568Z",
          "shell.execute_reply.started": "2023-12-26T06:49:10.059034Z",
          "shell.execute_reply": "2023-12-26T06:49:10.151770Z"
        },
        "trusted": true,
        "id": "d9hiajwt9Xhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert tokens to iob\n",
        "\n",
        "def span_to_iob(tokenized, starts, ends, text_labels):\n",
        "    tokens = tokenized.tokens()\n",
        "    aligned_labels = ['O'] * len(tokens)\n",
        "    # Make a list to store our labels the same length as our tokens\n",
        "    for start, end, label in zip(starts, ends, text_labels):\n",
        "        annotation_token_ix_set = (\n",
        "            set()\n",
        "        ) # A set that stores the token indices of the annotation\n",
        "        for char_ix in range(start, end):\n",
        "            token_ix = tokenized.char_to_token(char_ix)\n",
        "            if token_ix is not None:\n",
        "                annotation_token_ix_set.add(token_ix)\n",
        "        sorted_annotation_token_ix_set = sorted(annotation_token_ix_set)\n",
        "        for num, token_ix in enumerate(sorted_annotation_token_ix_set):\n",
        "            if num == 0: # or tokenized.token_to_word(token_ix) == tokenized.token_to_word(sorted_annotation_token_ix_set[0]):\n",
        "                prefix = 'B'\n",
        "            else:\n",
        "                prefix = 'I' # We're inside of a multi token annotation\n",
        "            aligned_labels[token_ix] = f\"{prefix}-{label}\"\n",
        "    return aligned_labels\n"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:11.131143Z",
          "iopub.execute_input": "2023-12-26T06:49:11.131863Z",
          "iopub.status.idle": "2023-12-26T06:49:11.157944Z",
          "shell.execute_reply.started": "2023-12-26T06:49:11.131814Z",
          "shell.execute_reply": "2023-12-26T06:49:11.156648Z"
        },
        "trusted": true,
        "id": "Go_ZhSGK9Xhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels = [span_to_iob(tokenizer([row[1][0]]), *row[1][1:])\n",
        "                for row in test_reviews[['text', 'span_start', 'span_end', 'text_label']].iterrows()]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:12.064718Z",
          "iopub.execute_input": "2023-12-26T06:49:12.065517Z",
          "iopub.status.idle": "2023-12-26T06:49:12.589120Z",
          "shell.execute_reply.started": "2023-12-26T06:49:12.065477Z",
          "shell.execute_reply": "2023-12-26T06:49:12.587842Z"
        },
        "trusted": true,
        "id": "uE3UDH5V9Xhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_reviews['labels'] = test_labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:12.911530Z",
          "iopub.execute_input": "2023-12-26T06:49:12.911974Z",
          "iopub.status.idle": "2023-12-26T06:49:12.923233Z",
          "shell.execute_reply.started": "2023-12-26T06:49:12.911941Z",
          "shell.execute_reply": "2023-12-26T06:49:12.921586Z"
        },
        "trusted": true,
        "id": "HhCLN2iX9Xhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build dataset\n",
        "\n",
        "from transformers import DataCollatorForTokenClassification, DefaultDataCollator, DataCollatorWithPadding\n",
        "\n",
        "# data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "class TokenDataset:\n",
        "    def __init__(self,\n",
        "                 df, label2id\n",
        "            ):\n",
        "        self.tokenized = tokenizer(df.text.tolist())\n",
        "        self.labels = df.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.tokenized.input_ids[idx]\n",
        "        attention_mask = self.tokenized.attention_mask[idx]\n",
        "        token_type_ids = self.tokenized.token_type_ids[idx]\n",
        "        labels = [label2id[ele] for ele in self.labels[idx]]\n",
        "\n",
        "        return {\n",
        "                'input_ids': input_ids,\n",
        "                'token_type_ids': token_type_ids,\n",
        "                'attention_mask': attention_mask,\n",
        "                'labels': labels\n",
        "               }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:13.543118Z",
          "iopub.execute_input": "2023-12-26T06:49:13.544309Z",
          "iopub.status.idle": "2023-12-26T06:49:13.556270Z",
          "shell.execute_reply.started": "2023-12-26T06:49:13.544267Z",
          "shell.execute_reply": "2023-12-26T06:49:13.554941Z"
        },
        "trusted": true,
        "id": "vsM2UvXn9Xhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = \\\n",
        " ['I-Service_neutral',\n",
        " 'B-Service_both',\n",
        " 'I-Interior_positive',\n",
        " 'B-Whole_negative',\n",
        " 'B-Service_neutral',\n",
        " 'B-Food_neutral',\n",
        " 'I-Price_negative',\n",
        " 'B-Interior_neutral',\n",
        " 'B-Whole_neutral',\n",
        " 'I-Food_positive',\n",
        " 'B-Price_negative',\n",
        " 'B-Interior_negative',\n",
        " 'B-Food_both',\n",
        " 'B-Service_positive',\n",
        " 'I-Whole_neutral',\n",
        " 'I-Food_negative',\n",
        " 'I-Interior_negative',\n",
        " 'B-Whole_both',\n",
        " 'I-Price_positive',\n",
        " 'I-Whole_both',\n",
        " 'O',\n",
        " 'I-Whole_negative',\n",
        " 'I-Interior_both',\n",
        " 'I-Price_both',\n",
        " 'I-Service_positive',\n",
        " 'I-Food_both',\n",
        " 'B-Service_negative',\n",
        " 'I-Service_both',\n",
        " 'B-Price_neutral',\n",
        " 'B-Food_positive',\n",
        " 'I-Food_neutral',\n",
        " 'B-Food_negative',\n",
        " 'I-Interior_neutral',\n",
        " 'B-Interior_both',\n",
        " 'I-Price_neutral',\n",
        " 'B-Price_positive',\n",
        " 'B-Price_both',\n",
        " 'B-Whole_positive',\n",
        " 'B-Interior_positive',\n",
        " 'I-Whole_positive',\n",
        " 'I-Service_negative']"
      ],
      "metadata": {
        "id": "qQXpYw3IU1X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i: label for i, label in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "test_set = TokenDataset(test_reviews, label2id)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:14.230982Z",
          "iopub.execute_input": "2023-12-26T06:49:14.231460Z",
          "iopub.status.idle": "2023-12-26T06:49:14.442397Z",
          "shell.execute_reply.started": "2023-12-26T06:49:14.231420Z",
          "shell.execute_reply": "2023-12-26T06:49:14.441356Z"
        },
        "trusted": true,
        "id": "T3jZ_R_b9Xhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        ").to('cuda')"
      ],
      "metadata": {
        "id": "ypgW7yiMVkRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Предсказания"
      ],
      "metadata": {
        "id": "IaSatWO45z8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pass output of tokenizer to device\n",
        "def tokenized_to_cuda(text):\n",
        "    tokenized = tokenizer([text], return_tensors='pt')\n",
        "    for key in tokenized:\n",
        "        tokenized[key] = tokenized[key].to('cuda')\n",
        "    return tokenized\n",
        "\n",
        "def predict_labels(texts, model):\n",
        "    return [\n",
        "        [id2label[ele.item()] for ele in model(**tokenized_to_cuda(text)).logits.argmax(dim=-1)[0]]\n",
        "    for text in texts]\n",
        "\n",
        "test_preds = predict_labels(test_reviews.text, model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:49:31.244202Z",
          "iopub.execute_input": "2023-12-26T06:49:31.244956Z",
          "iopub.status.idle": "2023-12-26T06:49:42.334824Z",
          "shell.execute_reply.started": "2023-12-26T06:49:31.244895Z",
          "shell.execute_reply": "2023-12-26T06:49:42.332424Z"
        },
        "trusted": true,
        "id": "UNZJqAhm9Xhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iob_to_span(tokenized, iob_labels):\n",
        "    tokens = tokenized.tokens()\n",
        "    starts, ends, text_labels = [], [], []\n",
        "    for i, (token, label) in enumerate(zip(tokens, iob_labels)):\n",
        "        span = tokenized.token_to_chars(i)\n",
        "        if span is not None:\n",
        "            start, end = span\n",
        "            if label.startswith('B') or label.startswith('I'):\n",
        "                starts.append(start)\n",
        "                ends.append(end)\n",
        "                text_labels.append(label)\n",
        "\n",
        "    merged_starts, merged_ends, merged_text_labels = starts[:1], [], text_labels[:1]\n",
        "    for i, label in enumerate(text_labels):\n",
        "        if label.startswith('B'):\n",
        "            merged_ends.append(ends[i-1])\n",
        "            merged_starts.append(starts[i])\n",
        "            merged_text_labels.append(label[2:])\n",
        "    merged_ends.append(ends[-1])\n",
        "\n",
        "    return merged_starts[1:], merged_ends[1:], merged_text_labels[1:]"
      ],
      "metadata": {
        "id": "yhw8DScXzKbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for start, end, ent in zip(*iob_to_span(tokenizer(test_reviews.text[0]), test_preds[0])):\n",
        "    print(test_reviews.text[0][start:end], start, end, ent, sep='\\t')"
      ],
      "metadata": {
        "id": "76YvR_y4Bp3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58145ad8-6046-4c39-b988-d97e6aea5742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "менеджер- темноволосая\t147\t169\tService_neutral\n",
            "девушка, проводила к столу и дала меню\t179\t217\tService_positive\n",
            "официантка\t242\t252\tService_neutral\n",
            "приняла заказ\t254\t267\tService_positive\n",
            "удалил\t270\t276\tService_negative\n",
            "ждать\t315\t320\tService_positive\n",
            "ресторан\t337\t345\tWhole_positive\n",
            "заведения\t431\t440\tWhole_positive\n",
            "Бизнес ланч\t495\t506\tFood_positive\n",
            "цене\t582\t586\tPrice_positive\n",
            "место\t610\t615\tWhole_positive\n",
            "меню\t639\t643\tFood_positive\n",
            "цены\t656\t660\tPrice_positive\n",
            "качество обслуживания\t671\t692\tService_positive\n",
            "заведению\t735\t744\tWhole_positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сохраняем результаты NER"
      ],
      "metadata": {
        "id": "McIyplD3-dH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test_pred_aspects.txt', 'w') as f:\n",
        "    for review_id, text, preds in zip(test_reviews.review_id.tolist(),\n",
        "                                      test_reviews.text.tolist(),\n",
        "                                      test_preds):\n",
        "        for start, end, ent in zip(*iob_to_span(tokenizer(text), preds)):\n",
        "            token = text[start:end]\n",
        "            aspect, sentiment = ent.split('_')\n",
        "            print(review_id, aspect, token, start, end, sentiment, sep='\\t', end='\\n', file=f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:51:54.939909Z",
          "iopub.execute_input": "2023-12-26T06:51:54.940355Z",
          "iopub.status.idle": "2023-12-26T06:51:55.600672Z",
          "shell.execute_reply.started": "2023-12-26T06:51:54.940319Z",
          "shell.execute_reply": "2023-12-26T06:51:55.597307Z"
        },
        "trusted": true,
        "id": "1LK9GeHi9Xhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сохраняем результаты ABSA"
      ],
      "metadata": {
        "id": "TKbdXMQD-lUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем упоминания аспектов с предсказанной тональностью, припишем\n",
        "\n",
        "-   ```absence``` - если нет упоминаний данной категории\n",
        "- ```both``` - если есть упоминания с разной тональностью\n",
        "- ```positive/neutral/negative``` - если все упоминания одной тональности"
      ],
      "metadata": {
        "id": "T07oRPvY8iPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORIES = ['Whole', 'Interior', 'Service', 'Food', 'Price']"
      ],
      "metadata": {
        "id": "-7Jpr4Bt8AxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_full_sentiment(text, max_len=5):\n",
        "    asp_counter = defaultdict(Counter)\n",
        "    for start, end, ent in zip(*iob_to_span(tokenizer(text), preds)):\n",
        "        aspect, sentiment = ent.split('_')\n",
        "        asp_counter[aspect][sentiment] += 1\n",
        "    for c in CATEGORIES:\n",
        "        if not asp_counter[c]:\n",
        "            s = 'absence'\n",
        "        elif len(asp_counter[c]) == 1:\n",
        "            s = asp_counter[c].most_common(1)[0][0]\n",
        "        else:\n",
        "            s = 'both'\n",
        "        yield c, s"
      ],
      "metadata": {
        "id": "cWo1l1UZ8C45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test_pred_cats.txt', 'w') as f:\n",
        "    for review_id, text, preds in zip(test_reviews.review_id.tolist(),\n",
        "                                  test_reviews.text.tolist(),\n",
        "                                  test_preds):\n",
        "        for aspect, sentiment in get_full_sentiment(text):\n",
        "            print(review_id, aspect, sentiment, sep='\\t', end='\\n', file=f)"
      ],
      "metadata": {
        "id": "UTkXeDhJ89yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка 1: accuracy по выделению упоминаний с категориями"
      ],
      "metadata": {
        "id": "k3g0N-yN9Xhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_aspects_test_path = '/content/test_pred_aspects.txt'\n",
        "pred_cats_test_path = '/content/test_pred_cats.txt'"
      ],
      "metadata": {
        "id": "C0Xw55SmWBCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_ner(gold_test_path, pred_test_path):\n",
        "    gold_aspect_cats = {}\n",
        "    with open(gold_test_path) as fg:\n",
        "        for line in fg:\n",
        "            line = line.rstrip('\\r\\n').split('\\t')\n",
        "            if line[0] not in gold_aspect_cats:\n",
        "                gold_aspect_cats[line[0]] = {'starts':[], 'ends':[], 'cats':[], 'sents':[]}\n",
        "            gold_aspect_cats[line[0]]['starts'].append(int(line[3]))\n",
        "            gold_aspect_cats[line[0]]['ends'].append(int(line[4]))\n",
        "            gold_aspect_cats[line[0]]['cats'].append(line[1])\n",
        "            gold_aspect_cats[line[0]]['sents'].append(line[5])\n",
        "\n",
        "    full_match, partial_match, full_cat_match, partial_cat_match = 0, 0, 0, 0\n",
        "    total = 0\n",
        "    fully_matched_pairs = []\n",
        "    partially_matched_pairs = []\n",
        "    with open(pred_test_path) as fp:\n",
        "        for line in fp:\n",
        "            total += 1\n",
        "            line = line.rstrip('\\r\\n').split('\\t')\n",
        "            start, end = int(line[3]), int(line[4])\n",
        "            category = line[1]\n",
        "            doc_gold_aspect_cats = gold_aspect_cats[line[0]]\n",
        "            if start in doc_gold_aspect_cats['starts']:\n",
        "                i = doc_gold_aspect_cats['starts'].index(start)\n",
        "                if doc_gold_aspect_cats['ends'][i] == end:\n",
        "                    full_match += 1\n",
        "                    if doc_gold_aspect_cats['cats'][i] == category:\n",
        "                        full_cat_match += 1\n",
        "                    else:\n",
        "                        partial_cat_match += 1\n",
        "                    fully_matched_pairs.append(\n",
        "                        (\n",
        "                            [\n",
        "                                doc_gold_aspect_cats['starts'][i],\n",
        "                                doc_gold_aspect_cats['ends'][i],\n",
        "                                doc_gold_aspect_cats['cats'][i],\n",
        "                                doc_gold_aspect_cats['sents'][i]\n",
        "                            ],\n",
        "                            line\n",
        "                        )\n",
        "                    )\n",
        "                    continue\n",
        "            for s_pos in doc_gold_aspect_cats['starts']:\n",
        "                if start <= s_pos:\n",
        "                    i = doc_gold_aspect_cats['starts'].index(s_pos)\n",
        "                    if doc_gold_aspect_cats['ends'][i] == end:\n",
        "                        partial_match += 1\n",
        "                        partially_matched_pairs.append(\n",
        "                            (\n",
        "                                [\n",
        "                                    doc_gold_aspect_cats['starts'][i],\n",
        "                                    doc_gold_aspect_cats['ends'][i],\n",
        "                                    doc_gold_aspect_cats['cats'][i],\n",
        "                                    doc_gold_aspect_cats['sents'][i]\n",
        "                                ],\n",
        "                                line\n",
        "                            )\n",
        "                        )\n",
        "                        if doc_gold_aspect_cats['cats'][i] == category:\n",
        "                            partial_cat_match += 1\n",
        "                        continue\n",
        "                    matched = False\n",
        "                    for e_pos in doc_gold_aspect_cats['ends'][i:]:\n",
        "                        if s_pos <= end <= e_pos:\n",
        "                            partial_match += 1\n",
        "                            partially_matched_pairs.append(\n",
        "                                (\n",
        "                                    [\n",
        "                                        doc_gold_aspect_cats['starts'][i],\n",
        "                                        doc_gold_aspect_cats['ends'][i],\n",
        "                                        doc_gold_aspect_cats['cats'][i],\n",
        "                                        doc_gold_aspect_cats['sents'][i]\n",
        "                                    ],\n",
        "                                    line\n",
        "                                )\n",
        "                            )\n",
        "                            if doc_gold_aspect_cats['cats'][i] == category:\n",
        "                                partial_cat_match += 1\n",
        "                            matched = True\n",
        "                            break\n",
        "                    if matched:\n",
        "                        break\n",
        "                if start > s_pos:\n",
        "                    i = doc_gold_aspect_cats['starts'].index(s_pos)\n",
        "                    if start < doc_gold_aspect_cats['ends'][i] <= end:\n",
        "                        partial_match += 1\n",
        "                        partially_matched_pairs.append(\n",
        "                            (\n",
        "                                [\n",
        "                                    doc_gold_aspect_cats['starts'][i],\n",
        "                                    doc_gold_aspect_cats['ends'][i],\n",
        "                                    doc_gold_aspect_cats['cats'][i],\n",
        "                                    doc_gold_aspect_cats['sents'][i]\n",
        "                                ],\n",
        "                                line\n",
        "                            )\n",
        "                        )\n",
        "                        if doc_gold_aspect_cats['cats'][i] == category:\n",
        "                            partial_cat_match += 1\n",
        "                        break\n",
        "\n",
        "    gold_size = sum([len(gold_aspect_cats[x]['cats']) for x in gold_aspect_cats])\n",
        "\n",
        "    print(f\"\"\"\n",
        "    Full match precision: {full_match / total}\n",
        "    Full match recall: {full_match / gold_size}\n",
        "    Partial match ratio in pred: {(full_match + partial_match)  / total}\n",
        "    Full category accuracy: {full_cat_match / total}\n",
        "    Partial category accuracy: {(full_cat_match + partial_cat_match) / total}\n",
        "    \"\"\")\n",
        "\n",
        "    return fully_matched_pairs, partially_matched_pairs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-26T06:52:44.399504Z",
          "iopub.execute_input": "2023-12-26T06:52:44.399995Z",
          "iopub.status.idle": "2023-12-26T06:52:44.437799Z",
          "shell.execute_reply.started": "2023-12-26T06:52:44.399955Z",
          "shell.execute_reply": "2023-12-26T06:52:44.436420Z"
        },
        "trusted": true,
        "id": "5bofc3EX9Xhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бейзлайн"
      ],
      "metadata": {
        "id": "IfmznmvTIj03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fully_matched_pairs_baseline, partially_matched_pairs_baseline = \\\n",
        "evaluate_ner(gold_aspects_test_path, baseline_aspects_test_path)"
      ],
      "metadata": {
        "id": "nErOLa0SIGF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ec67cc-1612-4e2a-f496-40c79cef6278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Full match precision: 0.48\n",
            "    Full match recall: 0.7159663865546219\n",
            "    Partial match ratio in pred: 0.6197183098591549\n",
            "    Full category accuracy: 0.46422535211267607\n",
            "    Partial category accuracy: 0.6033802816901408\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наша модель"
      ],
      "metadata": {
        "id": "i8bBMBQ1IldH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fully_matched_pairs, partially_matched_pairs = \\\n",
        "evaluate_ner(gold_aspects_test_path, pred_aspects_test_path)"
      ],
      "metadata": {
        "id": "Cvra1Wk2Iiwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a59d45d-47a1-4b3f-8957-0f8dcac8ffea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Full match precision: 0.6527559055118111\n",
            "    Full match recall: 0.6966386554621848\n",
            "    Partial match ratio in pred: 0.8047244094488188\n",
            "    Full category accuracy: 0.621259842519685\n",
            "    Partial category accuracy: 0.789763779527559\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка 2: accuracy по тональности упоминаний"
      ],
      "metadata": {
        "id": "e2c6CFWGBwTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_accuracy(matches):\n",
        "    matched_sentiment = 0.\n",
        "    for pair in matches:\n",
        "        *_, gold_s = pair[0]\n",
        "        *_, pred_s = pair[1]\n",
        "        if gold_s == pred_s:\n",
        "            matched_sentiment += 1\n",
        "    return matched_sentiment / len(matches)"
      ],
      "metadata": {
        "id": "kWFe1NbkJSAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бейзлайн"
      ],
      "metadata": {
        "id": "FO8E0EqxHOP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy по полностью совпавшим упоминаниям: {sentiment_accuracy(fully_matched_pairs_baseline)}')\n",
        "print(f'Accuracy по частично совпавшим упоминаниям: {sentiment_accuracy(partially_matched_pairs_baseline)}')"
      ],
      "metadata": {
        "id": "l8mOitq6HN9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91da25a-47fd-4be9-8149-7dd676434e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy по полностью совпавшим упоминаниям: 0.6772300469483568\n",
            "Accuracy по частично совпавшим упоминаниям: 0.6370967741935484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наша модель"
      ],
      "metadata": {
        "id": "LYswcKn0J73-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy по полностью совпавшим упоминаниям: {sentiment_accuracy(fully_matched_pairs)}')\n",
        "print(f'Accuracy по частично совпавшим упоминаниям: {sentiment_accuracy(partially_matched_pairs)}')"
      ],
      "metadata": {
        "id": "LDRVDzu0J-In",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7fcee5-e420-40ef-8112-a4a985185daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy по полностью совпавшим упоминаниям: 0.8202653799758746\n",
            "Accuracy по частично совпавшим упоминаниям: 0.7357512953367875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка 3: accuracy по тональности категории"
      ],
      "metadata": {
        "id": "KK15o_hgKD_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overall_sentiment_accuracy(gold_cats_test_path, pred_cats_test_path):\n",
        "    with open(gold_cats_test_path) as gc, open(pred_cats_test_path) as pc:\n",
        "        gold_labels = set(gc.readlines())\n",
        "        pred_labels = set(pc.readlines())\n",
        "        print(\n",
        "            'Overall sentiment accuracy:',\n",
        "            len(gold_labels & pred_labels) / len(gold_labels)\n",
        "        )"
      ],
      "metadata": {
        "id": "XuNLl7JGKDYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бейзлайн:"
      ],
      "metadata": {
        "id": "OlIJwDWtMOuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_sentiment_accuracy(gold_cats_test_path, baseline_cats_test_path)"
      ],
      "metadata": {
        "id": "FD0he1VFMQqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba81054f-dc5b-4a59-db60-2f5484acfea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall sentiment accuracy: 0.523943661971831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наша модель:"
      ],
      "metadata": {
        "id": "2TocEuykMnux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_sentiment_accuracy(gold_cats_test_path, pred_cats_test_path)"
      ],
      "metadata": {
        "id": "mFSjYRIKMpVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b3d2b3-6005-486c-fc2e-ca4311e81dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall sentiment accuracy: 0.5859154929577465\n"
          ]
        }
      ]
    }
  ]
}